{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25354fe9-9ec4-4987-a1a9-0f39900a8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc39544-5a3c-4896-9688-6cc6ed183827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521b4c3-bc87-4896-9e38-9b7ca5d4be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess: reshape and normalize to [0, 1] range\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8043b8-d995-4d33-8230-b07555b7b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical (one-hot encoding)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e9e37-2353-4ed3-a182-c3fc611d52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Split training data into train and validation sets\n",
    "# This keeps the test set completely unseen until final evaluation\n",
    "validation_split = 0.1667  # This gives us 10,000 validation samples from 60,000 total\n",
    "split_index = int(len(train_images) * (1 - validation_split))\n",
    "train_imgs = train_images[:split_index]\n",
    "train_lbls = train_labels[:split_index]\n",
    "val_imgs = train_images[split_index:]\n",
    "val_lbls = train_labels[split_index:]\n",
    "\n",
    "print(f\"Training Samples: {len(train_imgs)}\")\n",
    "print(f\"Validation Samples: {len(val_imgs)}\")\n",
    "print(f\"Test Samples: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558351e-9516-493c-9f05-cad9cb49e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# First convolutional block\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "# Flatten the feature maps into a 1D vector\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense layers with dropout for regularization\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output layer with 10 units (one per digit class)\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589beb84-6a5e-499f-aeec-55a6284fbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5af9a-d8ea-49b6-8585-2820ee6ca9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary to see architecture\n",
    "print('\\n Model Architecture:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d827a55-ca8b-4d2e-8d7f-8b7b97b2eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks for smarter training\n",
    "# Early stopping: stops training when validation loss stops improving\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', # Watch the validation loss\n",
    "    patience=3,         # Stop if no improvement for 3 epochs\n",
    "    restore_best_weights=True, # Restore the best model weights\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68c7f9-dac4-4cac-aaf7-b5aff57b6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint: saves the best model during training\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_mnist_model.keras', # File to save the model\n",
    "    monitor='val_accuracy',  # Watch validation accuracy\n",
    "    save_best_only=True,    # Only save when we beat the previous best\n",
    "    mode='max',               # Higher accuracy is better\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3594f-3882-4e1a-a17d-7ab501fda0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with validation data and callbacks\n",
    "print(\"\\nStarting training...\")\n",
    "history = model.fit(train_imgs, train_lbls,\n",
    "                    epochs=20,   # Set a high number; early stopping will handle it\n",
    "                    batch_size=64, # Use proper validation set\n",
    "                    validation_data=(val_imgs, val_lbls),  # Apply our smart training callbacks\n",
    "                    callbacks=[early_stop, checkpoint],\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991e477-3bd5-4c67-bb82-98f70bdb8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set (completely unseen data)\n",
    "print('\\nEvaluating on test set...')\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('\\nFinal Results:')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "print(f'Test accuracy: {test_acc:.4f} ({test_acc*100:.2}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f115f-11d1-47eb-b4d9-d615f62fd1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on a few test samples to verify\n",
    "print(\"\\nSample Predictions:\")\n",
    "predictions = model.predict(test_images[:10], verbose=0)\n",
    "\n",
    "for i in range(10):\n",
    "    predicted_class = predictions[i].argmax()\n",
    "    true_class = test_labels[i].argmax()\n",
    "    confidence = predictions[i].max() * 100\n",
    "    status = '✓' if predicted_class == true_class else '✗'\n",
    "    print(f'{status} Prediction: {predicted_class}, True: {true_class}, Confidence: {confidence:.1f}%')\n",
    "    print(f'Prediction {predictions[i].argmax()}, True label: {test_labels[i].argmax()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c7a76-d35a-4942-b9d7-f7f0a8cc1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history to visualize learning\n",
    "print(f\"Total epochs trained: {len(history.history['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcf5c0-1a3b-4ba9-9ece-9ecdf3814f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss over epochs\n",
    "# This shows how \"wrong\" the model is over time (lower is better)\n",
    "ax1.plot(history.history['loss'], label='Training Loss', linewidth=2, marker='o')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2, marker='s')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Model Loss During Training', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotation explaining what we want to see\n",
    "ax1.text(0.02, 0.98,\n",
    "         'Good: Both curves decrease together\\nBad: Training drops but validation rises (overfitting)',\n",
    "        transform=ax1.transAxes, fontsize=9, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "# Plot 2: Accuracy over epochs  \n",
    "# This shows how \"correct\" the model is over time (higher is better)\n",
    "ax2.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, marker='o')\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, marker='s')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.set_title('Model Accuracy During Training', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotation\n",
    "ax2.text(4.9, 0.92,\n",
    "         'Good: Both curves increase together\\nBad: Training climbs but validation plateaus',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3)\n",
    ")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fd2bc-49c8-4eea-ac57-4bda75437899",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = history.history['val_accuracy'].index(max(history.history['val_accuracy'])) + 1\n",
    "print(f'Best validation accuracy achieved at epoch: {best_epoch}')\n",
    "print(f'Best validation accuracy: {max(history.history['val_accuracy']):.4f}')\n",
    "print(f'Final training accuracy: {history.history['accuracy'][-1]:.4f}')\n",
    "print(f'Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50bce24-c5df-4d35-9458-71985b9d5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting signs\n",
    "train_val_gap = history.history['accuracy'][-1] - history.history['val_accuracy'][-1]\n",
    "if train_val_gap > 0.5:\n",
    "    print(f'\\n Warning: Training accuracy is {train_val_gap:.2%} higher than validation')\n",
    "    print(f'This suggest overfitting. Consider adding more dropout or regularization.')\n",
    "else:\n",
    "    print(f'\\n Good: Training and validation accuracy are close (gap: {train_val_gap:.2%})')\n",
    "    print('  The model is generalizing well!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
